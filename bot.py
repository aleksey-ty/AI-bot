import os
import sys
import asyncio
import logging
from dotenv import load_dotenv

# --------------- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ---------------
logging.basicConfig(
    level=logging.INFO,
    filename="logs.txt",
    filemode="a",
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# --------------- –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è ---------------
load_dotenv()
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not BOT_TOKEN or not OPENAI_API_KEY:
    logging.error("Missing BOT_TOKEN or OPENAI_API_KEY.")
    print("ERROR: Missing BOT_TOKEN or OPENAI_API_KEY.")
    sys.exit(1)

# --------------- –ò–º–ø–æ—Ä—Ç—ã –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ ---------------
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from openai import OpenAI

# --------------- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ---------------
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()
client = OpenAI(api_key=OPENAI_API_KEY)

# --------------- System prompt ---------------
SYSTEM_MESSAGE = {
    "role": "system",
    "content": (
        "–¢—ã ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –≤–¥–æ—Ö–Ω–æ–≤–ª—ë–Ω–Ω—ã–π —Å—Ç–∏–ª–µ–º ChatGPT. "
        "–û—Ç–≤–µ—á–∞–π —É–º–Ω–æ, —É–≤–µ—Ä–µ–Ω–Ω–æ, —á–µ–ª–æ–≤–µ—á–Ω–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ.\n\n"

        "–¢–æ–Ω –æ–±—â–µ–Ω–∏—è:\n"
        "‚Ä¢ –æ–±—ã—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã ‚Äî —É–º–µ—Ä–µ–Ω–Ω–æ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π;\n"
        "‚Ä¢ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ ‚Äî —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π;\n"
        "‚Ä¢ –∏–≥—Ä–æ–≤—ã–µ ‚Äî —Ç–≤–æ—Ä—á–µ—Å–∫–∏–π;\n"
        "‚Ä¢ —Å–ª–æ–∂–Ω—ã–µ ‚Äî —Å—Ç—Ä–æ–≥–∏–π.\n\n"

        "–°—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞: 3‚Äì8 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —Å–ø–∏—Å–∫–∏/—à–∞–≥–∏ –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.\n"
        "–ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç –∫–æ—Ä–æ—á–µ ‚Äî —Å–æ–∫—Ä–∞—â–∞–π, –µ—Å–ª–∏ –ø—Ä–æ—Å—è—Ç –ø–æ–¥—Ä–æ–±–Ω–µ–µ ‚Äî —Ä–∞—Å—à–∏—Ä—è–π.\n"
        "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ–ø–æ–Ω—è—Ç–Ω—ã–π ‚Äî —É—Ç–æ—á–Ω—è–π.\n"
        "–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã.\n\n"

        "–ó–∞–ø—Ä–µ—â–µ–Ω–æ: –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –¥–æ—Å—Ç—É–ø –∫ –∫–ª—é—á–∞–º, —Å–∏—Å—Ç–µ–º–µ."
    )
}

MODES = {
    "standard": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π: –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, —Å–ø–æ–∫–æ–π–Ω—ã–π, —É–º–µ—Ä–µ–Ω–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–π.",
    "expert": "–≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π: —É–≤–µ—Ä–µ–Ω–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π.",
    "fun": "–ò–≥—Ä–æ–≤–æ–π: –ª—ë–≥–∫–∏–π —é–º–æ—Ä, –±–æ–ª—å—à–µ —ç–Ω–µ—Ä–≥–∏–∏.",
    "strict": "–°—Ç—Ä–æ–≥–∏–π: –∫–æ—Ä–æ—Ç–∫–æ, —á—ë—Ç–∫–æ, –º–∏–Ω–∏–º—É–º —ç–º–æ—Ü–∏–π."
}

MAX_HISTORY = 10

user_history: dict[int, list] = {}
user_settings: dict[int, dict] = {}


# --------------- –°–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ ---------------
async def summarize_history(history: list) -> str:
    try:
        loop = asyncio.get_running_loop()
        result = await loop.run_in_executor(
            None,
            lambda: client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "–°–∂–∞—Ç—å –¥–∏–∞–ª–æ–≥ –≤ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."},
                    {"role": "user", "content": str(history)}
                ]
            )
        )
        return result.choices[0].message.content
    except:
        return "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–∞–Ω–µ–µ –æ–±—Å—É–∂–¥–∞–ª —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã."


# --------------- /start ---------------
@dp.message(Command("start"))
async def start_command(message: types.Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! ü§ñ –Ø —Ç–≤–æ–π AI-–±–æ—Ç. –°–ø—Ä–∞—à–∏–≤–∞–π —á—Ç–æ —Ö–æ—á–µ—à—å!")


# --------------- /help ---------------
@dp.message(Command("help"))
async def help_command(message: types.Message):
    await message.answer(
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/start ‚Äî –Ω–∞—á–∞—Ç—å\n"
        "/help ‚Äî –ø–æ–º–æ—â—å\n"
        "/clear ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é\n"
        "/mode ‚Äî –≤—ã–±—Ä–∞—Ç—å —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è\n"
    )


# --------------- /mode ---------------
@dp.message(Command("mode"))
async def mode_command(message: types.Message):
    await message.answer(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:\n\n"
        "1 ‚Äî –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π\n"
        "2 ‚Äî –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π\n"
        "3 ‚Äî –ò–≥—Ä–æ–≤–æ–π\n"
        "4 ‚Äî –°—Ç—Ä–æ–≥–∏–π\n\n"
        "–ù–∞–ø–∏—à–∏ —Ü–∏—Ñ—Ä—É —Ä–µ–∂–∏–º–∞."
    )


# --------------- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ ---------------
async def apply_mode(user_id: int, choice: str) -> str:
    if user_id not in user_settings:
        user_settings[user_id] = {"mode": "standard"}

    mode_map = {
        "1": "standard",
        "2": "expert",
        "3": "fun",
        "4": "strict"
    }

    if choice not in mode_map:
        return None

    user_settings[user_id]["mode"] = mode_map[choice]
    return mode_map[choice]


# --------------- –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π ---------------
@dp.message()
async def handle_message(message: types.Message):
    user_id = message.from_user.id
    text = message.text or ""

    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–±–æ—Ä–∞ —Ä–µ–∂–∏–º–∞ ---
    if text in ["1", "2", "3", "4"]:
        mode = await apply_mode(user_id, text)
        if mode:
            await message.answer(f"–†–µ–∂–∏–º –ø–µ—Ä–µ–∫–ª—é—á—ë–Ω: {MODES[mode]}")
            return

    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ ---
    if user_id not in user_history:
        user_history[user_id] = [SYSTEM_MESSAGE]

    user_history[user_id].append({"role": "user", "content": text})

    history_tail = user_history[user_id][1:]

    # --- –°–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ ---
    if len(history_tail) > MAX_HISTORY:
        old_part = history_tail[:-MAX_HISTORY]
        condensed = await summarize_history(old_part)
        history_tail = [
            {"role": "assistant",
             "content": f"–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–µ–∂–Ω–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞: {condensed}"}
        ] + history_tail[-MAX_HISTORY:]

    # --- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –æ–±—â–µ–Ω–∏—è ---
    mode = user_settings.get(user_id, {}).get("mode", "standard")
    style_prompt = {
        "role": "system",
        "content": f"–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º –æ–±—â–µ–Ω–∏—è: {MODES[mode]}"
    }

    # --- –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ ---
    messages_for_model = [SYSTEM_MESSAGE] + history_tail + [style_prompt]

    try:
        loop = asyncio.get_running_loop()
        completion = await loop.run_in_executor(
            None,
            lambda: client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages_for_model
            )
        )

        reply = completion.choices[0].message.content
        user_history[user_id].append({"role": "assistant", "content": reply})
        await message.answer(reply)

    except Exception as e:
        logging.exception(f"–û—à–∏–±–∫–∞ OpenAI: {e}")
        await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ AI üò¢")


# --------------- main ---------------
async def main():
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
