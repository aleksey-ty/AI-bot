import os
import sys
import asyncio
import logging
from dotenv import load_dotenv

# --------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---------------
logging.basicConfig(
    level=logging.INFO,
    filename="logs.txt",
    filemode="a",
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# --------------- –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ---------------
load_dotenv()
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not BOT_TOKEN or not OPENAI_API_KEY:
    logging.error("Missing BOT_TOKEN or OPENAI_API_KEY in environment. Exiting.")
    print("ERROR: Missing BOT_TOKEN or OPENAI_API_KEY.")
    sys.exit(1)

# --------------- –ò–º–ø–æ—Ä—Ç—ã ---------------
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from openai import OpenAI

# --------------- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ ---------------
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()
client = OpenAI(api_key=OPENAI_API_KEY)

# --------------- System prompt ---------------
SYSTEM_MESSAGE = {
    "role": "system",
    "content": (
        "–¢—ã ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π Telegram-–±–æ—Ç-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ GPT-4o-mini.\n"
        "–û—Ç–≤–µ—á–∞–π —á—ë—Ç–∫–æ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∏ –∫—Ä–∞—Ç–∫–æ.\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–º–µ—Ä—ã, —Å–ø–∏—Å–∫–∏ –∏ —à–∞–≥–∏, –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ.\n"
        "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ–ø–æ–Ω—è—Ç–Ω—ã–π ‚Äî —É—Ç–æ—á–Ω–∏.\n"
        "–ï—Å–ª–∏ –Ω–µ–ª—å–∑—è –æ—Ç–≤–µ—á–∞—Ç—å ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ –±–µ–∑–æ–ø–∞—Å–Ω—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É.\n"
    )
}

MAX_HISTORY = 10
user_history: dict[int, list] = {}


# --------------- –°–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ ---------------
async def summarize_history(history: list) -> str:
    try:
        loop = asyncio.get_running_loop()
        result = await loop.run_in_executor(
            None,
            lambda: client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "–°–∂–∞—Ç—å –¥–∏–∞–ª–æ–≥ –≤ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."},
                    {"role": "user", "content": str(history)}
                ]
            )
        )
        return result.choices[0].message.content
    except Exception as e:
        logging.exception(f"–û—à–∏–±–∫–∞ —Å–∂–∞—Ç–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")
        return "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–∞–Ω–µ–µ –æ–±—Å—É–∂–¥–∞–ª —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã."


# --------------- –û–±—Ä–∞–±–æ—Ç—á–∏–∫ /start ---------------
@dp.message(Command("start"))
async def start_command(message: types.Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! ü§ñ –Ø —Ç–≤–æ–π AI-–±–æ—Ç. –°–ø—Ä–∞—à–∏–≤–∞–π —á—Ç–æ —Ö–æ—á–µ—à—å!")
    logging.info(f"User {message.from_user.id} started bot.")


# --------------- –ì–ª–∞–≤–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–∞ ---------------
@dp.message()
async def handle_message(message: types.Message):
    user_id = message.from_user.id
    text = message.text or ""
    logging.info(f"Incoming from {user_id}: {text}")

    # –°–æ–∑–¥–∞—ë–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
    if user_id not in user_history:
        user_history[user_id] = [SYSTEM_MESSAGE]

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_history[user_id].append({"role": "user", "content": text})

    # –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –∏—Å—Ç–æ—Ä–∏–∏ (–±–µ–∑ system)
    history_tail = user_history[user_id][1:]

    # –ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è ‚Äî —Å–∂–∏–º–∞–µ–º —Å—Ç–∞—Ä—É—é —á–∞—Å—Ç—å
    if len(history_tail) > MAX_HISTORY:
        old_part = history_tail[:-MAX_HISTORY]
        condensed = await summarize_history(old_part)

        history_tail = [
            {"role": "assistant", "content": f"–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–µ–∂–Ω–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞: {condensed}"}
        ] + history_tail[-MAX_HISTORY:]

    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
    messages_for_model = [SYSTEM_MESSAGE] + history_tail

    # –î–æ–±–∞–≤–∏–º –º—è–≥–∫—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
    messages_for_model.append({
        "role": "system",
        "content": "–ï—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏ –∏–ª–∏ —à–∞–≥–∏."
    })

    # –ó–∞–ø—Ä–æ—Å –∫ OpenAI
    try:
        loop = asyncio.get_running_loop()
        completion = await loop.run_in_executor(
            None,
            lambda: client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages_for_model
            )
        )

        reply = completion.choices[0].message.content
        user_history[user_id].append({"role": "assistant", "content": reply})
        await message.answer(reply)

    except Exception as e:
        logging.exception(f"–û—à–∏–±–∫–∞ OpenAI: {e}")
        await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ AI üò¢")


# --------------- –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ---------------
async def main():
    logging.info("Bot is starting...")
    try:
        await dp.start_polling(bot)
    finally:
        logging.info("Bot stopped.")


if __name__ == "__main__":
    asyncio.run(main())
